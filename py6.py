import sys
import cv2
import torch
import numpy as np
import threading  # ğŸ“Œ Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Threading Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ÙˆØ§Ø²ÛŒ
from PySide6.QtWidgets import QApplication, QMainWindow, QStatusBar, QLabel
from PySide6.QtGui import QImage, QPixmap
from PySide6.QtCore import QTimer, Qt
from coreYoloV5.utils.torch_utils import select_device
from coreYoloV5.utils.general import non_max_suppression
from coreYoloV5.utils.plots import Annotator, colors
from coreYoloV5.models.common import DetectMultiBackend

import time  # ğŸ“Œ Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ø¨Ø±Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ù‡ FPS

class CameraApp(QMainWindow):
    def __init__(self):
        super().__init__()
        self.initUI()
        self.initCamera()
        self.loadModel()
        self.running = True
        self.frame = None
        self.processed_frame = None

        # âœ… Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ FPS
        self.frame_count = 0
        self.last_time = time.time()

        # Ø§Ø¬Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ YOLO Ø¯Ø± Thread Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡
        self.processing_thread = threading.Thread(target=self.yolo_processing, daemon=True)
        self.processing_thread.start()


    def initUI(self):
        """ ØªÙ†Ø¸ÛŒÙ… Ø±Ø§Ø¨Ø· Ú©Ø§Ø±Ø¨Ø±ÛŒ """
        self.showFullScreen()
        self.image_label = QLabel(self)
        self.setCentralWidget(self.image_label)
        self.status_bar = QStatusBar(self)
        self.setStatusBar(self.status_bar)

        self.left_label = QLabel("Ø³Ù„Ø§Ù…Øª Ø³ÛŒØ³ØªÙ…", self)
        self.left_label.setAlignment(Qt.AlignLeft)
        self.left_label.setStyleSheet("background-color: blue; color: white; padding: 5px;")
        self.right_label = QLabel("Ø³Ù„Ø§Ù…Øª Ù†Ø§Ø®Ù†", self)
        self.right_label.setAlignment(Qt.AlignRight)
        self.right_label.setStyleSheet("background-color: gray; color: white; padding: 5px;")

        self.status_bar.addPermanentWidget(self.left_label, 1)
        self.status_bar.addPermanentWidget(self.right_label, 1)

    def loadModel(self):
        """ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„ YOLOv5 """
        self.device = select_device("")  # Ø§Ù†ØªØ®Ø§Ø¨ CPU ÛŒØ§ GPU
        self.model = DetectMultiBackend("weights/img1024_notSorting.pt", device=self.device)
        self.names = self.model.names  # Ú©Ù„Ø§Ø³â€ŒÙ‡Ø§ÛŒ Ù…Ø¯Ù„
        self.stride = int(self.model.stride)  # Ù…Ù‚Ø¯Ø§Ø± stride Ù…Ø¯Ù„

    def initCamera(self):
        """ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙˆÛŒØ¯ÛŒÙˆ ÛŒØ§ Ø¯ÙˆØ±Ø¨ÛŒÙ† """
        self.cap = cv2.VideoCapture('files/input_video.mp4')
        # self.cap = cv2.VideoCapture('output_2025-01-31_11-48-58.mp4')

        # ØªÙ†Ø¸ÛŒÙ… ØªØ§ÛŒÙ…Ø± Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ ÙØ±ÛŒÙ…â€ŒÙ‡Ø§
        self.timer = QTimer(self)
        self.timer.timeout.connect(self.update_frame)
        self.timer.start(30)  # Ù†Ù…Ø§ÛŒØ´ Ù‡Ø± Û³Û° Ù…ÛŒÙ„ÛŒâ€ŒØ«Ø§Ù†ÛŒÙ‡

    def yolo_processing(self):
        """ Ù¾Ø±Ø¯Ø§Ø²Ø´ YOLO Ø¯Ø± Thread Ø¬Ø¯Ø§Ú¯Ø§Ù†Ù‡ Ø¨Ø±Ø§ÛŒ Ø§ÙØ²Ø§ÛŒØ´ Ø³Ø±Ø¹Øª """
        while self.running:
            if self.frame is not None:
                self.processed_frame = self.process_frame(self.frame.copy())  # Ù¾Ø±Ø¯Ø§Ø²Ø´ YOLO

    def update_frame(self):
        """ Ø¯Ø±ÛŒØ§ÙØª ÙØ±ÛŒÙ… Ø¬Ø¯ÛŒØ¯ØŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ùˆ Ù†Ù…Ø§ÛŒØ´ FPS """
        ret, frame = self.cap.read()
        if ret:
            self.frame = frame  # Ø°Ø®ÛŒØ±Ù‡ ÙØ±ÛŒÙ… Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´
            if self.processed_frame is not None:
                display_frame = self.processed_frame
            else:
                display_frame = frame

            # âœ… Ù…Ø­Ø§Ø³Ø¨Ù‡ FPS
            self.frame_count += 1
            current_time = time.time()
            elapsed_time = current_time - self.last_time

            if elapsed_time >= 1.0:  # Ù‡Ø± 1 Ø«Ø§Ù†ÛŒÙ‡ ÛŒÚ© Ø¨Ø§Ø± Ø¨Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø´ÙˆØ¯
                fps = self.frame_count / elapsed_time
                self.left_label.setText(f"FPS: {fps:.2f}")  # Ù†Ù…Ø§ÛŒØ´ FPS Ø¯Ø± Ù†ÙˆØ§Ø± ÙˆØ¶Ø¹ÛŒØª
                self.frame_count = 0
                self.last_time = current_time

            # ØªØ¨Ø¯ÛŒÙ„ ÙØ±ÛŒÙ… Ø¨Ù‡ RGB Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø± PySide6
            display_frame = cv2.cvtColor(display_frame, cv2.COLOR_BGR2RGB)
            h, w, ch = display_frame.shape
            q_img = QImage(display_frame.data, w, h, ch * w, QImage.Format_RGB888)

            # ØªØºÛŒÛŒØ± Ø§Ù†Ø¯Ø§Ø²Ù‡ ØªØµÙˆÛŒØ± Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´ Ù…Ù†Ø§Ø³Ø¨ Ø¯Ø± QLabel
            pixmap = QPixmap.fromImage(q_img)
            screen_size = self.image_label.size()
            scaled_pixmap = pixmap.scaled(screen_size, Qt.KeepAspectRatio, Qt.SmoothTransformation)

            self.image_label.setPixmap(scaled_pixmap)  # Ù†Ù…Ø§ÛŒØ´ Ø¯Ø± QLabel

    def process_frame(self, im0):
        """ YOLO Ø±ÙˆÛŒ ØªØµÙˆÛŒØ± Ú©ÙˆÚ†Ú©â€ŒØªØ± Ø§Ø¬Ø±Ø§ Ø´Ø¯Ù‡ Ùˆ Ø®Ø±ÙˆØ¬ÛŒ Ø¨Ù‡ Ø§Ù†Ø¯Ø§Ø²Ù‡ Ø§ØµÙ„ÛŒ Ø¨Ø§Ø²Ú¯Ø±Ø¯Ø§Ù†Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯ """

        # Ø§Ø¨Ø¹Ø§Ø¯ Ø§ØµÙ„ÛŒ ØªØµÙˆÛŒØ±
        h0, w0 = im0.shape[:2]

        # ğŸ”¹ ØªØºÛŒÛŒØ± Ø§Ù†Ø¯Ø§Ø²Ù‡ ØªØµÙˆÛŒØ± ÙÙ‚Ø· Ø¨Ø±Ø§ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´ YOLO (Ù…Ø«Ù„Ø§Ù‹ 640x480)
        input_w, input_h = 640, 640
        im_resized = cv2.resize(im0, (input_w, input_h))

        # Ù†Ø³Ø¨Øª ØªØºÛŒÛŒØ± Ø§Ù†Ø¯Ø§Ø²Ù‡
        width_ratio = w0 / input_w
        height_ratio = h0 / input_h

        # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ ÙØ±Ù…Øª YOLO: (C, H, W)
        img = torch.from_numpy(im_resized).to(self.device)
        img = img.float() / 255.0
        img = img.permute(2, 0, 1).unsqueeze(0)

        # Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ø§ Ù…Ø¯Ù„ YOLO
        pred = self.model(img)
        pred = non_max_suppression(pred, conf_thres=0.45, iou_thres=0.45)

        # Ø±Ø³Ù… Ø®Ø±ÙˆØ¬ÛŒ Ø±ÙˆÛŒ ØªØµÙˆÛŒØ± Ø§ØµÙ„ÛŒ
        annotator = Annotator(im0, line_width=2)
        for det in pred:
            if det is not None and len(det):
                det[:, [0, 2]] *= width_ratio
                det[:, [1, 3]] *= height_ratio
                det[:, :4] = det[:, :4].round()

                for *xyxy, conf, cls in reversed(det):
                    label = f"{self.names[int(cls)]} {conf:.2f}"
                    annotator.box_label(xyxy, label, color=colors(int(cls), True))

        return annotator.result()  # Ù†Ù…Ø§ÛŒØ´ Ø¯Ø± GUI Ø¨Ø§ Ø§Ù†Ø¯Ø§Ø²Ù‡ Ø§ØµÙ„ÛŒ

    def closeEvent(self, event):
        """ Ø¢Ø²Ø§Ø¯ Ú©Ø±Ø¯Ù† Ù…Ù†Ø§Ø¨Ø¹ Ù‡Ù†Ú¯Ø§Ù… Ø¨Ø³ØªÙ† Ø¨Ø±Ù†Ø§Ù…Ù‡ """
        self.running = False  # Ù…ØªÙˆÙ‚Ù Ú©Ø±Ø¯Ù† Ù¾Ø±Ø¯Ø§Ø²Ø´
        self.cap.release()
        event.accept()

if __name__ == '__main__':
    app = QApplication(sys.argv)
    window = CameraApp()
    window.show()
    sys.exit(app.exec())
